{
    "collab_server" : "",
    "contents" : "library(caret)\nlibrary(reshape2)\nlibrary(glmnet)\n\n#### Function to split data to  folds based on y value ####\n\nnfolds <- 5\nfoldindex <- createFolds(vtreatment$crossFrame$SalePrice,nfolds,list = FALSE)\n\n\n\n#### Model Parameters ####\n\n#xgboost parameters\nXGBparams <- list( colsample_bytree=0.4,\n                gamma=0.045,                 \n                learning_rate=0.07,\n                max_depth=20,\n                min_child_weight=1.5,\n                reg_alpha=0.65,\n                reg_lambda=0.45,\n                subsample=0.95)\n\n#glmnet Parameters\nalpha <- 1\n\n\n#### Functions to fit a model on one fold of the data ####\n\nFitFoldXGB <- function(mode = \"train\", data, fold = NULL, model = NULL, y = NULL){\nif (mode == \"train\"){\n  ### code to train an XGBOOST model\n  dtrain <- xgb.DMatrix(data[foldindex != fold,], label = y[foldindex != fold], missing = NaN)\n  mdl <- xgboost(data = dtrain, nround=100, nthread = 4, metrics=list(\"rmse\"),params = XGBparams, objective = \"reg:linear\", verbose = 0)\n  yhat <- predict(mdl,newdata = data[foldindex == fold,], missing = NaN)\n  list(modelFit = mdl, yhat = yhat, y =  y[foldindex == fold], id = which(foldindex == fold), alpha = alpha)\n} else {\n  ### code to score an arbitrary xgboost model on a new set of data\n  predict(model, newdata = data, missing = NaN)\n}\n}\n  \n\n\nFitFoldGLMNET <- function(mode = \"train\", data, fold = NULL, model = NULL, y = NULL){\nif (mode == \"train\"){\n  glmnetmodel <- cv.glmnet(x = data[foldindex != fold,], y = log(y[foldindex != fold]), type.measure = \"mse\")\n  mdl <- glmnetmodel\n  yhat <- exp(predict(glmnetmodel, newx = data[foldindex == fold,], s = \"lambda.min\", type = \"response\"))\n  list(modelFit = mdl, yhat = yhat, y =  y[foldindex == fold], id = which(foldindex == fold))\n} else {\n  exp(predict(model,newx = data, s = \"lambda.min\", type = \"response\"))\n}\n}\n\n\n\n\n\n#### Function to fit model on each fold and return a set of models, validation results and L1 predictions ####\nCVFit <- function(fitfunc, data, y){\n  lfeature <- NULL\n  accuracy <- NULL\n  models <- NULL\n  for(i in 1:nfolds){\n    foldfit <- do.call(fitfunc,list(mode = \"train\", fold = i, data = data, y = y))\n    lfeature <- rbind(lfeature,data.table(l1x = foldfit[[\"yhat\"]],id = foldfit[[\"id\"]]))\n    accuracy <- c(accuracy,sqrt(mean((log(foldfit[[\"yhat\"]])-log(foldfit[[\"y\"]]))^2)))\n    models[[i]] <- foldfit[[\"modelFit\"]]\n  }\n  lfeature <- lfeature[order(lfeature$id),]\n  list(models = models, lfeature = lfeature, accuracy = accuracy)\n}\n  \n\n#### Function to score nested models on new data and return average prediction for each new data pont ###\nCVScore <- function(Models, data, scoreFunction){\n  scores <- matrix(nrow = nrow(data),ncol = 0)\n  for(i in 1:nfolds){\n    scorefold <- do.call(scoreFunction,list(mode = \"test\", fold = i, data = data, model = Models[[i]]))\n    scores <- cbind(scores,scorefold)\n  }\n  rowMeans(scores)\n}\n\n\n\n\n\n##### Call CVFit for each model type to create level 1 predictors ####\n\nXGBL1 <- CVFit(\"FitFoldXGB\", data = model_matrix,  y = model_y)\nmean(XGBL1[[\"accuracy\"]])\n\n\nGLMNETL1 <- CVFit(\"FitFoldGLMNET\", data = model_matrix, y = model_y)\nmean(GLMNETL1[[\"accuracy\"]])\n\n\n\n#### Create add features to level 1 set for training level 2 ####\n\nmodel_matrix_L2 <- cbind(model_matrix, XGBL1 = XGBL1[[\"lfeature\"]]$l1x)\nmodel_matrix_L2 <- cbind(model_matrix_L2, GLMNETL1 = GLMNETL1[[\"lfeature\"]]$l1x)\n\n\n\n\n#### Train level two model ####\n\nGLMNETL2 <- CVFit(\"FitFoldGLMNET\", data = model_matrix_L2, y = model_y)\nmean(XGBL2[[\"accuracy\"]])\n\n\n\n\n#### Test Set Level 1 Predictions ####\n\nGLMNETL1.Test <- CVScore(GLMNETL1$models,test_matrix,\"FitFoldGLMNET\")\nXGBL1.Test <- CVScore(XGBL1$models,test_matrix,\"FitFoldXGB\")\n\ntest_matrix_L2 <- cbind(test_matrix, XGBL1 = XGBL1.Test)\ntest_matrix_L2 <- cbind(test_matrix_L2, GLMNETL1 = GLMNETL1.Test)\n\n\n#### Test Set Level 2 Predictions ####\n\n\nGLMNETL2.Test <- CVScore(GLMNETL2$models,test_matrix_L2,\"FitFoldGLMNET\")\n\n#### Output Test Predictions for Competition ####\ncombinedpredictions <- data.frame(Id = tstdata$Id,SalePrice = GLMNETL2.Test)\nwrite.csv(combinedpredictions, file = \"submission10.csv\", row.names = FALSE)\n\n\n\n\n",
    "created" : 1478125633772.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "2384419372",
    "id" : "69479057",
    "lastKnownWriteTime" : 1479659492,
    "last_content_update" : 1479659492818,
    "path" : "~/Kaggle/HousePrices/ModelStack.R",
    "project_path" : "ModelStack.R",
    "properties" : {
        "tempName" : "Untitled1"
    },
    "relative_order" : 2,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}